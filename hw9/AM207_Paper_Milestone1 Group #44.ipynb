{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APMTH 207: Advanced Scientific Computing: \n",
    "## Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "## Group Project -- Milestone 1\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Tuesday, November 13th, 2018 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on a Recent Research Development\n",
    "\n",
    "As part of the requirements for this course we've stated the following(quoting the website): \"There will be one paper, towards the end of this course. It will require reading and presenting a recent research development in the field.\"\n",
    "\n",
    "We've compiled a list of papers that contain interesting treatments of topics related to AM207:\n",
    "\n",
    "https://docs.google.com/document/d/1N0FjmMHfpX8P__TAzWLQYXqtj_Hbgo839Gu3B0oKOaM/edit?usp=sharing\n",
    "\n",
    "If you find a paper not on this list that you would like to delve into for your project, please let us know (and we can add it).\n",
    "\n",
    "We want you to create a tutorial style jupyter notebook summarizing the relevant math, methods and procedure in a paper of your choice.  Your tutorial should show the relevant methods in action by implementing them on appropriately chosen data.\n",
    "\n",
    "At this point you should have organized yourself into a group and have chosen (and been assigned a paper topic).  In this milestone, please give us  the name of your group(s) in Canvas, the name and url of your paper, and suggested assigned teaching staff member(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Paper(s) (give us the title and url):**\n",
    "<br>\n",
    "<br>\n",
    "**1st choice**\n",
    "<br>\n",
    "-- Paper Title: Bayesian GAN\n",
    "<br>\n",
    "-- Paper Url: https://arxiv.org/pdf/1705.09558.pdf\n",
    "<br>\n",
    "-- Brief Description: In their paper, Yunus Saatchi and Andrew Gordon Wilson argue that applying Bayesian framework to general adversarial network (GAN) would help prevent  mode collapse and result in a more straightforward and accurate model without feature matching or mini-batch discrimination. Specifically, they tackle GAN through a lens of fully probabilistic inference and marginalize the weights of the generator and discriminator using stochastic gradient Hamiltonian Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd choice**\n",
    "<br>\n",
    "-- Paper Title: Harnessing Model Uncertainty for Detecting Adversarial Examples\n",
    "<br>\n",
    "-- Paper Url: http://bayesiandeeplearning.org/2017/papers/37.pdf\n",
    "<br>\n",
    "-- Brief Description: In their paper, Ambrish Rawat, Martin Wistuba, and Maria-Irina Nicolae employ Bayesian neural networks (BNN) to gain a better grasp on Deep Learning models' uncertainty and reduce their vulnerability to adversarial attacks. Specifically the authors develop 4 different BNN's and simulate adversarial attacks with the help of Monte Carlo sampling. The models demonstrate increased prediction uncertainty when faced with crafted images and the author's believe that this discovery can be deployed as a new framework for detecting adversarial images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3rd choice**\n",
    "<br>\n",
    "-- Paper Title: Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\n",
    "<br>\n",
    "-- Paper Url:https: https://arxiv.org/abs/1506.02142\n",
    "<br>\n",
    "-- Brief Description: In an effort to ascertain uncertainty at an affordable computational cost, Yarin Gal and Zoubin Ghahramani make a strong case for using dropout training in deep neural networks to approximate Bayesian inference for  deep Gaussian processes. The paper claims, that this approach provides a better model for uncertainty, while preserving model accuracy and complexity at a manageable computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Members of the Group (give us the names and emails of all collaborators):**\n",
    "\n",
    "-- Collaborator 1: Dylan Randle dylanrandle@g.harvard.edu\n",
    "\n",
    "-- Collaborator 2: Michael S. Emanuel mse999@g.harvard.edu\n",
    "\n",
    "-- Collaborator 3: Anna Davydova davydova@g.harvard.edu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Group(Name of Project Group in Canvas):**\n",
    "\n",
    "-- Project Group Name (FAS): PaperTutorial 44\n",
    "\n",
    "-- Project Group Name (DCE):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teaching Staff Member(s) we'd like to discuss our project with:**\n",
    "\n",
    "-- Teaching Staff Member 1: Patrick Ohiomoba\n",
    "\n",
    "-- Teaching Staff Member 2: Srivatsan Srinivasan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
