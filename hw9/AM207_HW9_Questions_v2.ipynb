{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date:** Sunday, November 11th, 2018 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers in the form of a Jupyter notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "\n",
    "** Place the name of everyone who's submitting this assignment here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import cm\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "# pymc3 and theano imports\n",
    "\n",
    "import pymc3 as pm\n",
    "from pymc3 import Normal, Binomial, sample, Model \n",
    "from pymc3.math import invlogit\n",
    "from theano import shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: If I Sample the Works of the Brothers Gibb does that make me Bivariate Normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coding required**\n",
    "\n",
    "Let $\\mathbf{X}$ be a random variable taking values in $\\mathbb{R}^2$. That is, $\\mathbf{X}$ is a 2-dimensional vector. Suppose that $\\mathbf{X}$ is normally distributed as follows\n",
    "$$ \n",
    "\\mathbf{X} \\sim \\mathcal{N} \\left(  \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    1  \\\\ \n",
    "    2  \\\\ \n",
    "  \\end{array} \n",
    "\\right],\n",
    "\\left[\n",
    "  \\begin{array}{ccc}\n",
    "    4 & 1.2  \\\\ \n",
    "    1.2 & 4 \\\\ \n",
    "  \\end{array} \n",
    "  \\right] \\right).\n",
    "$$ \n",
    "That is, the pdf of the distribution of $\\mathbf{X}$ is\n",
    "$$\n",
    "f_{\\mathbf{X}}(\\mathbf{x}) = \\frac{1}{2\\pi\\sqrt{\\vert \\Sigma\\vert }}\\mathrm{exp}\\left\\{ - \\frac{1}{2} (\\mathbf{x} - \\mu)^\\top \\Sigma^{-1} (\\mathbf{x} - \\mu)\\right\\}\n",
    "$$\n",
    "where $\\mu = \\left[\n",
    "\\begin{array}{c}\n",
    "    1  \\\\ \n",
    "    2  \\\\ \n",
    "  \\end{array} \n",
    "\\right]$, $\\Sigma = \\left[\n",
    "  \\begin{array}{ccc}\n",
    "    4 & 1.2  \\\\ \n",
    "    1.2 & 4 \\\\ \n",
    "  \\end{array} \n",
    "  \\right]$, and $\\vert \\dots \\vert $ is the matrix determinant operator.\n",
    "\n",
    "In the following questions, we will denote the random variable corresponding to the first component of $\\mathbf{X}$ by $X_1$ and the second component by $X_2$.\n",
    "\n",
    "3.1. Write down the two conditional distributions $f_{X_1 \\vert X_2}, f_{X_2 \\vert X_1}$\n",
    "\n",
    "3.2. Write a Gibbs sampler for this distribution by sampling sequentially from the two conditional distributions $f_{X_1\\vert X_2}, f_{X_2\\vert X_1}$. \n",
    "\n",
    "3.3. Choose a thinning parameter, burn-in factor and total number of iterations that allow you to take 10000 non-autocorrelated draws. \n",
    "\n",
    "3.4. Plot a 2-d histogram of your samples, as well histograms of the $X_1$ and $X_2$ marginals.  Overlay on your histograms of the marginals a plot of the appropriate marginal density fitted with parameters derived from your marginal samples.\n",
    "\n",
    "3.4. Present traceplots and autocorrelation plots for your marginal samples.  Is your choice of parameters justified? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gratuitous Titular Reference**:  We've been accused of being overly cool in our music choices, so maybe it's time for something more [Normal](https://www.youtube.com/watch?v=jNJGl_jZTzc) (mixtape by Grime MC Merky ACE].  To take it a bit more old school, the Gibb brothers more commonly known as [The Beegees](https://en.wikipedia.org/wiki/Bee_Gees), were one of the most prominent bands in the 70s Disco movement (along with Donna Summer).  They're famous for songs like [More than a Woman](https://www.youtube.com/watch?v=fy0rYUvn7To), [To Love Somebody](https://www.youtube.com/watch?v=QHtGu0OGEpc) and of course [Stayin' Alive](https://www.youtube.com/watch?v=XfwQ_7xqO7Y).  Speaking of grimey London and mixups, [hold tight](https://www.urbandictionary.com/define.php?term=hold%20tight) former Arsenal fullback and top man Kieran Gibbs who provides a  great example of what happens when a referee tries Gibbs sampling but [samples the wrong distribution](https://youtu.be/FaZWMqOAveA?t=61).  [They all look the same, right](https://en.wikipedia.org/wiki/Cross-race_effect)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Through the Snap Lense of a Galaxy Man and Superman, Metropolis's Hastings has no disrupting Comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coding required**\n",
    "\n",
    "You are a renowned observational astronomer working on gravitational lensing and you just got news about a source whose morphology appears distorted, most likely because there is a foreground source (an ensemble of mini black holes for which you know the mass and position) acting as a lens. Your gravitational lensing calculations indicate that the detected flux $F$ from the background source as a function of right ascencion ($x$) and declination ($y$) can be described by a modified Beale's function:\n",
    "\n",
    "$F(x,y) = \\exp\\left[-\\left(\\frac{x^2}{2\\sigma_x^2}+\\frac{y^2}{2\\sigma_y^2}\\right)\\right] \\log \\left[1.0+(1.5-x+xy)^2+(2.25-x+xy^2)^2+(2.625-x+xy^3)^2 \\right] $\n",
    "\n",
    "where $\\sigma_x = \\sigma_y = \\sqrt{10}$\n",
    "\n",
    "You are interested in observing this source with the Hubble Space Telescope, and you want to simulate beforehand how photons will form the image on the Hubble detector. You realize that a good way to do this is by sampling F(x,y) with a Monte Carlo method.\n",
    "\n",
    "2.1. Plot the modified Beale's function.\n",
    "\n",
    "2.2. Consider the following asymmetric function $q(x, y)$ as a proposal distribution:\n",
    "\n",
    "$q(x,y) = \\frac{1}{\\sqrt{2 \\pi \\gamma_1\\gamma_2}} {\\rm exp}\\left[-\\left(\\frac{(x-0.1)^2}{2 \\gamma_1^2} + \\frac{(y-0.1)^2}{2 \\gamma_2^2}\\right) \\right] $ \n",
    "\n",
    "where $\\gamma_1 = \\beta$, $\\gamma_2 = 1.5 \\cdot \\beta$, and $\\beta=1$ \n",
    "\n",
    "*Note: x and y are the coordinates of the proposed step if we center the coordinate system in our current position.*\n",
    "\n",
    "construct a Metropolis-Hastings algorithm along with a thinning parameter, burn-in factor and total number of iterations that allow you to produce  $N=25000$ non-autocorrelated samples from $F(x,y)$ with an initial position of $(x,y) = (5,-5)$. \n",
    "\n",
    "2.3. Plot a 2-d histogram of your samples, as well histograms of the $x$ and $y$ marginals. \n",
    "\n",
    "2.4. Present traceplots and autocorrelation plots for your marginal samples.\n",
    "\n",
    "2.5. Experiment to determine how $\\beta$ affects sampling by running your sampler with 5 $\\beta$ values in the range 0.1 to 40 (think about the appropriate order of magnitude of the $\\beta$ spacing). Visualize the marginal samples, traceplot and autocorrelation plot for each $\\beta$.\n",
    "\n",
    "2.6. Plot the accepted sample histories for each $\\beta$. What is the acceptance rate for each $\\beta$? \n",
    "\n",
    "2.7. Explain your results. What's the \"best\" value of $\\beta$?\n",
    "\n",
    "2.8.  Choose a symmetric proposal and construct a Metropolis algorithm along with a thinning parameter, burn-in factor and total number of iterations that allow you to produce  $N=25000$ non-autocorrelated samples from $F(x,y)$ with an initial position of $(x,y) = (5,-5)$. \n",
    "\n",
    "2.9. Plot a 2-d histogram of your samples from 2.8 as well histograms of the $x$ and $y$ marginals. \n",
    "\n",
    "2.10. Present traceplots and autocorrelation plots for your marginal samples.\n",
    "\n",
    "2.11. How do the results compare to those from Metropolis-Hastings in 2.2 - 2.7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gratuitous Titular References**:  [Snap](https://www.snapchat.com/) obviously has [lenses](https://www.reddit.com/r/SnapLenses/) which you may (or [may not](https://forum.xda-developers.com/note5/help/snapchat-lenses-t3202082)) be able to see on your [Galaxy](https://www.samsung.com/us/mobile/galaxy/) ... [far far away](https://en.wikipedia.org/wiki/Star_Wars_opening_crawl)...  \n",
    "\n",
    "[Man and Superman](https://en.wikipedia.org/wiki/Man_and_Superman) is an important play by the notable Irish playright George Bernard Shaw.  \n",
    "\n",
    "The [Bayeux Tapestry](https://en.wikipedia.org/wiki/Bayeux_Tapestry) is a historically important embroidered tapestry detailing the Norman conquest of Britain and in particular the [Battle of Hastings](https://en.wikipedia.org/wiki/Battle_of_Hastings), the decisive Norman victory that marked the beginning of Norman rule over England.  The tapestry is historically the first known depiction of [Halley's comet](https://en.wikipedia.org/wiki/Halley%27s_Comet).  \n",
    "\n",
    "[Metropolis]() is most famous as the the fictional city patrolled by the DC superhero [Superman]() whose streaking figure is the closest thing to a comet the denizens of Metropolis see in their celestial firmament.  Learn all about it [Metropolis](https://www.dccomics.com/blog/2018/01/30/announcing-metropolis-dcs-newest-live-action-tv-series), the newest live action tv series in the DC-verse (coming in 2019) which features Lois Lane and Lex Luthor but no Superman.\n",
    "\n",
    "[The Expanse](https://www.syfy.com/theexpanse) and [Krypton](https://www.syfy.com/krypton) are watchable too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Assay Assay Bio you don't seem to be Apprehendin' the general Gist..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coding required**\n",
    "\n",
    "#### Bioassay\n",
    "\n",
    "This question follows an example from Gelman's \"Bayesian Data Analysis\". It will walk you through using `pymc3`. Keep a browser tab open to the pymc3 API docs...you will need them.\n",
    "\n",
    "Bioassay (commonly used shorthand for biological assay), or biological standardisation is a type of scientific experiment. Bioassays are typically conducted to measure the effects of a substance on a living organism and are essential in the development of new drugs and in monitoring environmental pollutants. Both are procedures by which the potency (pharmacology) or the nature of a substance is estimated by studying its effects on living matter.\n",
    "\n",
    "In this experiment, various drug doses are administered to animals and a binary outcome (death) is noted. There are 4 groups of 5 animals each, different doses administered, and deaths recorded. We construct a model for $\\theta$ the binomial probabiliy of death, as a regression on dose through the logit$^{-1}$ function with two parameters (see below). We set imprecise normal priors on the regression coefficients, and pass the linear regression through the inverse logit function into a binomial likelihood."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "| Dose, x_i  | Number of   | Number of    | \n",
    "| log(g/ml)  | animals,n_i |  deaths, y_i |\n",
    "|:-----------|------------:|:------------:|\n",
    "| -0.86      |     5       |     0        |\n",
    "| -0.30      |     5       |     1        |\n",
    "| -0.05      |     5       |     3        |\n",
    "|  0.73      |     5       |     5        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll enter the data here. One subtlety: we'll need to create a \"shared\" theano array so that we can compute posterior predictives on a grid later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a theano shared variable to be able to exchange the data the model runs on\n",
    "\n",
    "# Log dose in each group\n",
    "log_dose = np.array([-.86, -.3, -.05, .73])\n",
    "\n",
    "# Let's make this a theano shared variable so that we can make predictions for new values later\n",
    "log_dose_shared = shared(log_dose)\n",
    "\n",
    "# Sample size in each group\n",
    "n = 5 * np.ones(4, dtype=int)\n",
    "\n",
    "# The sample size has to be a shared variable too\n",
    "n_shared = shared(n)\n",
    "\n",
    "# Outcomes\n",
    "deaths = np.array([0, 1, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood, since we have a success/fail experiment, is expressed as a Binomial:\n",
    "\n",
    "$$ P(D_i|\\theta_i) = p(y_i, n_i| \\theta_i) = {\\rm Binomial}( y_i, n_i \\vert \\theta_i)  \\,\\,\\,\\,    \\rm{for}\\,\\, i=1, \\ldots, 4$$\n",
    "\n",
    "where $\\theta$ is the rate of deaths which is modeled as a $\\rm{logit}^{-1}$:  \n",
    "\n",
    "$$ \\theta_i = {\\rm logit}^{-1}(\\alpha+\\beta x_i) \\,\\,\\,\\, \\rm{for} \\,\\, i=1, \\ldots, 4$$\n",
    "\n",
    "The prior $p(\\alpha, \\beta)$ is a product of independent priors on $\\alpha$ and $\\beta$.  Considering the likelihood and the prior, the posterior is then: \n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "p(\\alpha, \\beta \\vert y) &\\propto p(\\alpha)p(\\beta) \\prod_{i=1}^{k} p(y_i \\vert \\alpha, \\beta, n_i, x_i) \\\\\n",
    "                         &= p(\\alpha)p(\\beta)\\prod_{i=1}^{k} [{\\rm logit}^{-1}(\\alpha+\\beta x_i)]^{y_i} [ 1-{\\rm logit}^{-1}(\\alpha+\\beta x_i)]^{n_i-y_i} \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model in PyMC3\n",
    "\n",
    "The first step is to specify the probabilistic model in PyMC3. We'll assume the prior $p(\\alpha, \\beta)$ splits into independent priors for $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$p(\\alpha, \\beta) = p(\\alpha) \\times p(\\beta), $$\n",
    "\n",
    "and further assume identical non-informative normal $N(0, 100$) priors on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Model() as bioassay_model:\n",
    "\n",
    "    # Logit-linear model parameters\n",
    "    alpha = pm.Normal('alpha', 0, sd=100)\n",
    "    beta = pm.Normal('beta', 0, sd=100)\n",
    "\n",
    "    # Calculate probabilities of death\n",
    "    theta = pm.Deterministic(\"theta\", invlogit(alpha + beta * log_dose_shared))\n",
    "\n",
    "    # Data likelihood\n",
    "    obs_deaths = pm.Binomial('obs_deaths', n=n_shared, p=theta, observed=deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"284pt\" height=\"227pt\"\n",
       " viewBox=\"0.00 0.00 284.34 227.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 223)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-223 280.3385,-223 280.3385,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M46.3945,-8C46.3945,-8 224.3945,-8 224.3945,-8 230.3945,-8 236.3945,-14 236.3945,-20 236.3945,-20 236.3945,-143 236.3945,-143 236.3945,-149 230.3945,-155 224.3945,-155 224.3945,-155 46.3945,-155 46.3945,-155 40.3945,-155 34.3945,-149 34.3945,-143 34.3945,-143 34.3945,-20 34.3945,-20 34.3945,-14 40.3945,-8 46.3945,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.8945\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4</text>\n",
       "</g>\n",
       "<!-- beta -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>beta</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"62.3945\" cy=\"-201\" rx=\"62.2891\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.3945\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">beta ~ Normal</text>\n",
       "</g>\n",
       "<!-- theta -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>theta</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"201.3945,-147 69.3945,-147 69.3945,-111 201.3945,-111 201.3945,-147\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.3945\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">theta ~ Deterministic</text>\n",
       "</g>\n",
       "<!-- beta&#45;&gt;theta -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>beta&#45;&gt;theta</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M80.0657,-183.5708C89.01,-174.749 100.0316,-163.8784 109.8775,-154.1674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"112.4617,-156.5346 117.1236,-147.0206 107.5461,-151.5509 112.4617,-156.5346\"/>\n",
       "</g>\n",
       "<!-- alpha -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>alpha</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"209.3945\" cy=\"-201\" rx=\"66.8882\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"209.3945\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">alpha ~ Normal</text>\n",
       "</g>\n",
       "<!-- alpha&#45;&gt;theta -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>alpha&#45;&gt;theta</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191.4811,-183.5708C182.4143,-174.749 171.2417,-163.8784 161.261,-154.1674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.5237,-151.4856 153.9156,-147.0206 158.6422,-156.5027 163.5237,-151.4856\"/>\n",
       "</g>\n",
       "<!-- obs_deaths -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>obs_deaths</title>\n",
       "<ellipse fill=\"#d3d3d3\" stroke=\"#000000\" cx=\"135.3945\" cy=\"-57\" rx=\"92.8835\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.3945\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">obs_deaths ~ Binomial</text>\n",
       "</g>\n",
       "<!-- theta&#45;&gt;obs_deaths -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>theta&#45;&gt;obs_deaths</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M135.3945,-110.8314C135.3945,-103.131 135.3945,-93.9743 135.3945,-85.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"138.8946,-85.4132 135.3945,-75.4133 131.8946,-85.4133 138.8946,-85.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f16bca2cd68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.model_to_graphviz(bioassay_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm.model_to_graphviz above should return an output like the following:\n",
    "\n",
    "![](https://d1b10bmlvqabco.cloudfront.net/attach/jlo4e4ari3r4wd/j9vjyzv62x149/jo39alg3bjeq/bio_assay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the model-specification stage (before the data are observed), $\\alpha$, $\\beta$, $\\theta$, and $y$ (the observed number of deaths) are all random variables. Then we observe $y$ and condition on these observations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. ***Verifying Installation***:  Try and reproduce the model graph in the image above by running all the above code cells provided in **Question 3**.  A currect run means that theano was installed properly as a dependency for pymc3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. ***Finding MAP point estimates***:  the maximum a posteriori (MAP) estimate for a model is the mode of the posterior distribution and is generally found using numerical optimization methods. PyMC3 provides this functionality with the `pm.find_MAP`  function. By default, ```find_MAP``` uses the Broyden–Fletcher–Goldfarb–Shanno (BFGS) optimization algorithm. Use it to find the MAP of the parameters. Notice that `pymc3` will propagate the MAP to the deterministic $\\theta$ variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Sample from the `bioassay_model` model by using the `pm.sample` function by passing`pm.Metropolis()` stepper as the `step` parameter  and pass in the MAP estimate as a starting point using the 'start' parameter. Generate 50,000 samples. You will see a  warning message --`The number of effective samples is smaller than 10% for some parameters`.  For the purposes of this homework ignore the warning message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Remove a burnin period of the first 40% of the samples from the trace, then use `pm.traceplot` and `pm.plot_posterior` to visualize the traces and the marginal posteriors of our parameters, as well as a propagated $\\theta$ set for our probabilities. Also plot the joint-posterior of our parameters (using seaborn's `sns.kdeplot`, for example). Finally, use `pm.summary` to output a summary of our parameter inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. Use `pm.autocorrplot` to plot the autocorrelations from our sampler. What happens when you thin our trace to every fifth sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking convergence with chains***: It is in general impossible to guarantee that a MCMC has indeed reached convergenge,  but convergence diagnostics can detect lack of convergence.\n",
    "\n",
    "An *ad hoc* method to detect lack of convergence involves plotting the traces of chains initialized with different starting conditions. We can run more than one chain using the argument `njobs` of the  `sample` function (pymc3 runs 2 by default). If convergence has occurred, we would expect the chains to converge to the same value, and to have approximately the same variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6. Run 4 chains with different starting values of $\\alpha =$ 0.5, 5, 1.5, and 5. Plot histograms of the 4 traces (with burn-in samples removed). Do the histograms look similar? **(you may wish to use the `histtype=\"step\"` argument to `plt.hist` for a clearer comparison)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Obtaining the posterior predictive***:  Since this is a regression, the posterior predictive $p(y^{\\ast} \\mid x^{\\ast}, D)$ is now obtained at each of our doses. If we had stored our burnin-removed traces in the variable `tr1`, then the following code will give use a posterior predictive of shape `(num_samples_in_trace, num_data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with bioassay_model:\n",
    "    deaths_sim = pm.sample_ppc(tr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, what we want is being able to predict observations at new doses. We can create an array of new hypothetical doses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dose_to_predict = np.random.uniform(-0.8,0.7,size=50)\n",
    "log_dose_to_predict\n",
    "n_predict = n = 5 * np.ones(50, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now update the values of the shared theano variables we had created with the values for which we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing values here will also change values in the model\n",
    "log_dose_shared.set_value(log_dose_to_predict)\n",
    "n_shared.set_value(n_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply running `sample_ppc` will give us posterior-predictive samples at 50 doses. Do this, restricting ourselves to getting only 5000 samples at each dosage, rather than the `num_samples_in_trace` we would get otherwise. The shape of the output should be 500x50. Plot the predictive at 2-3 points on the dosage grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7. Plot the posterior predictive means against the dosage grid `log_dose_to_predict` we used above. Use `np.percentile` to get the 95% credible interval on the predictive at each dosage, and use this to plot errorbars. Plot the observed data and provide an interpretation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gratuitous Titular Reference**:  The [I say, I say, boy!](https://knowyourmeme.com/photos/605281-reaction-images) meme is the perfect mix of meme and [Foghorn Leghorn](https://en.wikipedia.org/wiki/Foghorn_Leghorn).  Of course there are [many](https://knowyourmeme.com/photos/1265646-jeff-sessions) [others](https://knowyourmeme.com/photos/992404-whoosh-you-missed-the-joke)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "nteract": {
   "version": "0.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
