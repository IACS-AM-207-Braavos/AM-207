{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APMTH 207: Advanced Scientific Computing: \n",
    "## Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "## Group Project -- Final Paper\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Tuesday, December 11th, 2018 at 11:59pm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group #44 Collaborators:**\n",
    "\n",
    "-- Collaborator 1: Dylan Randle dylanrandle@g.harvard.edu\n",
    "\n",
    "-- Collaborator 2: Michael S. Emanuel mse999@g.harvard.edu\n",
    "\n",
    "-- Collaborator 3: Anna Davydova davydova@g.harvard.edu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesians take on the Belamies\n",
    "\n",
    "### Bayesian GAN Paper Tutorial\n",
    "<br>\n",
    "Source: Saatchi Y., Gordon AW. 2017. Bayesian GAN. Advances in Neural Information Processing Systems 30 (NIPS), 2017. arXiv:1705.09558 [stat.ML]\n",
    "<br>\n",
    "URL: https://arxiv.org/pdf/1705.09558.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Outline:\n",
    "-- Abstract\n",
    "<br>\n",
    "-- Inroduction\n",
    "<br>\n",
    "-- Bayesian GAN Theory\n",
    "<br>\n",
    "-- Bayeisan GAN Implementation\n",
    "<br>\n",
    "-- Conclusions\n",
    "<br>\n",
    "-- Gratuitous Titular Reference\n",
    "<br>\n",
    "-- Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract: \n",
    "\n",
    "In their paper, Yunus Saatchi and Andrew Gordon Wilson argue that applying Bayesian framework to general adversarial network (GAN) would help prevent mode collapse and result in a more straightforward and accurate model without feature matching or mini-batch discrimination. Specifically, they tackle GAN through a lens of fully probabilistic inference and marginalize the weights of the generator and discriminator using stochastic gradient Hamiltonian Monte Carlo. Our analysis below follows closely in the author's footsteps as we re-create their framework for Bayesian GAN and apply their findings to several examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "Â \n",
    "#### GANs Defined: \n",
    "Generative Adversarial Networks (GANs), as the name suggests, contain two neural network adversaries - Generator and Discriminator - with one forging new data and the other discerning truth from deception. (Goodfellow et al., 2014b)[1]. The discriminator usually takes form of a convolutional network that aims to correctly identify a given label(usually an image) given a group of associated features. In other words the discriminator estimates p(y|X).  The generator, on the other hand, attempts to predict the features given a label (i.e. p(X|y)).  Thus, the generator learns the distribution of the data and then creates new data, while the discriminator attempts to correctly identify the label authenticity given the true data and the fake data coming from the generator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](OReillyGAN.png  )\n",
    "<br>\n",
    "Source: https://skymind.ai/wiki/generative-adversarial-network-gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At it's core, the generator aims to generate data that resembles the truth so closely that it fools the discriminator into classifying it as authentic. The discriminator has an opposite objective of catching generator's fakes. This internal standoff between these two powerful and evolving algorithms has been used for image generation and image enhancement and a growing list of other applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GAN Image Generation Example: \n",
    "Images below are 'fake celebrities' headshots that have been generated by GANs after extensive training on real celebrity photos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"600\" length='900' alt=\"portfolio_view\" src=fake_celebrities.jpg>\n",
    "<br>\n",
    "Credit: Nvidia\n",
    "<br>\n",
    "Source: https://nerdist.com/nvidia-ai-headshots-fake-celebrities/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GAN Image Enhancement Example:\n",
    "GANs have also done incredibly well in the field of image enhancement as can be seen from the comparative analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800\" length='2000' alt=\"portfolio_view\" src=enhanced_image.png  >\n",
    "<br>\n",
    "Credit: Ledig et al. (2016)\n",
    "<br>\n",
    "Source:https://arxiv.org/pdf/1701.00160.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN Formulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about GAN in mathematical terms, we note that the tension between the generator and the discriminator is a zero-sum game. Therefore, the loss functions offset each other as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}L^{(G)}=-L^{(D)}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opposing objectives of the generator and the discriminator can be summarized as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathop{min}_{\\textbf{G}}\n",
    "\\mathop{max}_{\\textbf{D}}\n",
    "E_{x\\sim P_{real}}[log(D(x))]+E_{z\\sim P_{noise}}[log(1-D(G(z)))]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that D estimates p(y|X).  In other words, D(x) outputs probability that a given true image is classified correctly. Conversely, 1-D(G(z)), is the probability of classifying the forged image produced by the generator as fake (recall z is our noise vector). Thus, the better the generator gets at forging the images it feeds to the discriminator the higher the value of D(G(z)) and (1-D(G(z)) starts to approach zero. The discriminator has the opposite goal as it attempts to minimize D(G(z)) down to zero by catching all the forgeries, while maximizing D(x). If it accomplishes this goal, we get a value closet to 0 (i.e. log(1)) for the second half of the expression above. The diagram below outlines the training process for the discriminator and the generator and their respective gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](gan_gradient.jpeg  )\n",
    "<br>\n",
    "Source:https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the discriminator's and the generator's conflicting objectives, it is not hard to see why training GANs is computationally expensive (i.e takes a long time to converge) and prone to several issues. Traditional GAN challenges include: 1) non-covergence; 2) big imbalance between the performance of D and G leading to overfitting; 3) mode collapse (generator memorizes the data and stops creating varied samples); 4) shrinking gradient when discriminator overpowers generator and as the result the generator stops learning; 5) sensitivity to hyperparameters. Bayesian approach to GAN aims to alleviate the mode collapse issues (more on this in the next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below provides another illustration of how GAN works with the MNIST data set. The discriminator trains on a data set of real hand written images, while the generator feeds on randomly generated noise to create fake hand written digits. It is then the discriminator's job to distinguish between real and fake images. As the generator gets better and better (more and more iterations) at producing forgeries, the discriminator gets better and spotting them. As this iterative process continues, we end up with a set of generated hand written images nearly indistinguishable from the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800\" length='12000' alt=\"portfolio_view\" src=GANdiagram.png  >\n",
    "<br>\n",
    "Source: https://skymind.ai/wiki/generative-adversarial-network-gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](MNIST_gan.gif )\n",
    "<br>\n",
    "Source: https://towardsdatascience.com/implementing-a-generative-adversarial-network-gan-dcgan-to-draw-human-faces-8291616904a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Motivation: \n",
    "While GANs have proven themselves to be quite powerful, they suffer from several issues as discussed briefly above. Specifically, instances of mode collapse have been noted when the generator ends up memorizing a handfull of training examples. In addition, the authors of the paper highlight the need for meaningful intervention to ensure stability of the network, that requires feature matching, label smoothing and mini-batch discrimination.  While we are less familiar with this terminology, several papers have been written on this topic by [Radfod, Metz and Chintala](https://arxiv.org/abs/1511.06434) as well as [Salimans et al.](https://arxiv.org/abs/1606.03498)[2,3].  The authors also note that most of the research aimed at fixing these issues has focused on finding a better divergence metric for the GAN model (i.e. using Wasserstein or f-divergences instead of Jensen-Shannon).  Yunus Saatchi and Andrew Gordon Wilson take a different approach and propose a Bayesian route toward a more stable GAN architecture. Specifically, the authors apply stochastic gradient Hamiltonian Monte Carlo methods to marginalize conditional posteriors over the weights of the generator and discriminator (more on this below). \n",
    "<br>\n",
    "<br>\n",
    "Bayesian approach makes sense as we think about the stability of the GAN model.  By learning full distributions over the generator and the discriminator network weights, we are going to end up with a much richer distribution and more diverse samples, which should make the GAN model less prone to getting stuck in one mode with a handful of memorized images or have imbalance issues.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian GAN Theory:\n",
    "#### Assumptions:\n",
    "Given our data set is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "D=\\{x^{(i)}\\};\n",
    "x^{(i)} \\sim p_{data}(x^{(i)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for distribution of:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p_{data}(x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the white noise vector from the diagram in the introduction. In this case the authors propose that we transform white noise z$\\sim$p(z) through our generator. The authors define the Generator and the Discriminator as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " G(z;\\theta_g)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " D(x;\\theta_d)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G and D are essentially neural networks with weight vectors $\\theta_g$ and $\\theta_d$ respectively.  Recall that traditional GAN considers just one $\\theta_g$ and one $\\theta_d$. Here we are looking at full distributions of these $\\theta$'s and will conduct the sampling process from our priors as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Sample from the  $\\theta_g$ posterior that parametarizes our generator defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " \\theta_g \\sim p(\\theta_g)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Sample z's which serves as the input for the generator defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " z^1,.....,z^n \\sim p(z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: Obtain distribution of x given the sampled z's and $\\theta_g$s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " \\tilde{x}^j=G(z^j;\\theta_g)\\sim p_{generator}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors then propose two approaches for posterior inference over our $\\theta$'s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Unsupervised Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the authors sample from the following conditional posteriors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_g|z,\\theta_d)\\propto\\big(\\prod_{i=1}^{n_g}D(G(z^i;\\theta_g);\\theta_d)\\big)p(\\theta_g|\\alpha_g)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we note above, this is a posterior for fake data points.  Where $p(\\theta_g|\\alpha_g)$ is a prior and our likelihood is wrapped in a product of discriminator probabilities for identifying the fake images as real. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_d|z,X,\\theta_g)\\propto\\prod_{i=1}^{n_d}D(x^i;\\theta_d)*\\prod_{i=1}^{n_g}(1-D(G(z^i,\\theta_g);\\theta_d))* p(\\theta_d|\\alpha_d)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a discriminator posterior. Here,  $p(\\theta_d|\\alpha_d)$ is a prior. The two likelihoods wrapped in the product functions are: 1) probability of identifying real data correctly and 2) probability of identifying fake data correctly ( a joint probability of being right). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha$'s and $n$'s are the corresponding hyperparameters and mini-batch samples respectively for both expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors define $X$ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " X = \\{x^i\\}_{i=i}^{n_d}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors use Monte Carlo to marginalize the noise component z from the posterior updates.  They demonstrate this as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_g|\\theta_d)= \\int p(\\theta_g,z|\\theta_d)dz=\\int p(\\theta_g|z,\\theta_d)p(z|\\theta_d)dz\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since $p(x)=p(z|\\theta_d)$, this reduces nicely to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_g|\\theta_d)\\approx\\frac{1}{J_g}\\sum_{j=1}^{J_g}p(\\theta_g|z^j,\\theta_d), z^j\\sim p(z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by the same token we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_d|\\theta_g)\\approx\\frac{1}{J_d}\\sum_{j=1}^{J_d}p(\\theta_d|z^j,X,\\theta_g), z^j\\sim p(z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then iteratively sample posteriors from $p(\\theta_d|\\theta_g)$ and $p(\\theta_g|\\theta_d)$. The authors argue that the varied samples of $\\theta_g$ reduce the risk of mode collapse (i.e. instead of one we now have a whole distribution of generators leading to much more diverse data samples and generated images) and boost the performance of the discriminator. This is then matched by the scope of  $\\theta_d$ samples that further strengthen the adversarial standoff between the generator and the discriminator, making the entire model more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Semi-Supervised Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For semi-supervised approach, we will consider a data set without labels and a much smaller slice of data with labels {1....K}. Here, our model simultaneously learns the distribution of x both for labeled and unlabeled observations. The authors believe that this modeling approach will produce better results than fully supervised or unsupervised learning. This makes sense intuitively but is also something we are going to test in the implementation section of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our discriminator as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " D(x^i=y^i;\\theta_d)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the discriminator now outputs the probability that a given x belongs to a given class y.  What this means is that instead of outputting probability of an image being real or fake, the discriminator actually classifies it into one of the labels in the label set {1....K}.  The authors use class y=0 for any x values coming from the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then have the following posteriors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_g|z,\\theta_d)\\propto\\big(\\prod_{i=1}^{n_g}\\sum_{y=1}^{K} D(G(z^i;\\theta_g)=y;\\theta_d)\\big)p(\\theta_g|\\alpha_g)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(\\theta_d|z,X,y_s,\\theta_g)\\propto\\prod_{i=1}^{n_d}\\sum_{y=1}^{K} D(x^i=y;\\theta_d)*\\prod_{i=1}^{n_g}(D(G(z^i,\\theta_g)=0;\\theta_d))* \\prod_{i=1}^{N_s}(D(x_s^i=y_s^i;\\theta_d))p(\\theta_d|\\alpha_d)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, structurally, the expressions above are much like the unsupervised posteriors from the previous section. The key difference is that now the likelihoods include the sum of specific class probabilities (i.e. likelihoods across different classes {1.....K}). Here we are also using three types of samples: 1) $n_g$ are the samples from the generator, 2) $n_d$ are the unlabeled samples and 3) $N_s$ are labeled observations that are contained in a slice that is much smaller than the total number of observations $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying what we already know from unsupervised approach above, we marginalize the posteriors over $\\theta_d$ and $\\theta_g$. The authors propose using an average of all the samples with respect to the posterior over $\\theta_d$ to estimate class y for a given instance of x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " p(y_j|x_j,D)=\\int p(y_j|x_j, \\theta_d)p(\\theta_d|D)d\\theta_d\\approx \\frac{1}{T}\\sum_{k=1}^{T}p(y_j|x_j,\\theta_d^k \\sim p(\\theta_d|D)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application of Stochastic Gradient HMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to marginalize the posteriors both for unsupervised and semi-supervised learning procedures over $\\theta_d$ and $\\theta_g$, the authors deploy Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) approach. They state three key reasons for this choice: 1) SGHMC is analogous to SGD (Stochastic Gradient Descent) that has proven to work well with GANs and 2)it allows the authors to import parameters such as learning rate, momentum etc. from SGD to SGHMC. 3) Finally, SGHMC best supports the author's goal to explore richer, multimodal distributions over $\\theta_g$ (i.e. weights of the generator). They argue that  other alternatives tend to provide unimodal distributions. We will not go into a lot of detail on this topic to prove/disprove the author's contention. However, there is a very detailed paper on the topic of SGHMC by [Chen et al](https://arxiv.org/abs/1402.4102)[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we present the author's algorithm in pseudocode. Things to keep in mind when reading this algorithm: 1) This is just one iteration of Bayesian GAN. 2) The authors define $\\alpha$ as the friction term for SGHMC and $\\eta$ as the learning rate. 3) During the simple MC sampling process, the authors take $J_d$ samples for the discriminator and $J_g$ samples for the generator. 4) They then take M SGHMC samples for each MC sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BGAN Algorithm with SGHMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From previous iteration of sampling, represent posteriors as follows:\n",
    "<br>\n",
    "${\\theta_g^{j,m}}_{j=1,m=1}^{J_g,M}$,${\\theta_d^{j,m}}_{j=1,m=1}^{J_d,M}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sample the generator as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For number of $J_g$ MC iterations:\n",
    "<br>\n",
    "    Sample $J_g$ samples of noise {$z^1,...,z^{J_g}$} from its prior p(z). Note, each $x^i$ has $n_g$ samples.\n",
    "    <br>\n",
    "    For M iterations, use SGHMC to update your set of posterior $p(\\theta_g|\\theta_d)$ samples as follows:\n",
    "        <br>\n",
    " $$ \\theta_{g}^{j,m} \\leftarrow \\theta_g^{j,m} + v; v\\leftarrow(1-\\alpha)v+\\eta\\big ( \\sum_{i=1}^{J_g}\\sum_{k=1}^{J_d}\\frac{\\partial log p(\\theta_g|z^i,\\theta_d^{k,m})}{\\partial \\theta_g}\\big)+n   $$\n",
    "<br>\n",
    "$$n\\sim N(0,2\\alpha\\eta I)$$\n",
    "<br>\n",
    "    Append $\\theta_g^{j,m}$ to our set of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sample the discriminator as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  For number of $J_d$ MC iterations:\n",
    "<br>\n",
    "    Take minibatch sized sample of $J_d$ noise samples{$z^1,.....,z^{J_d}$} like we did in step 2.\n",
    "    <br>\n",
    "    Take minibatch sized sample of $n_d$ samples of x from our data set \n",
    "    <br>\n",
    "    For M iterations, run SGHMC to update $p(\\theta_d|z,\\theta_g)$\n",
    "    <br>\n",
    "     $$ \\theta_{d}^{j,m} \\leftarrow \\theta_d^{j,m} + v; v\\leftarrow(1-\\alpha)v+\\eta\\big ( \\sum_{i=1}^{J_d}\\sum_{k=1}^{J_g}\\frac{\\partial log p(\\theta_d|z^i,x,\\theta_g^{k,m})}{\\partial \\theta_d}\\big)+n   $$\n",
    "<br>\n",
    "$$n\\sim N(0,2\\alpha\\eta I)$$\n",
    "<br>\n",
    "    Append $\\theta_d^{j,m}$ to our set of samples\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In a nutshell:\n",
    "For the generator $\\theta_g$, we produce $J_g$ samples by first sampling our noise and then running SGHMC to produce our $\\theta_g$ samples and taking the derivatives of log-likelihood w.r.t. $\\theta_g$ weights with our noise samples and discriminator $\\theta_d$. The authors also including the term n above that based on the SGHMC paper by [Chen et al](https://arxiv.org/abs/1402.4102) has a regularizing effect on noise in the algorithm.[4]  Once we get our new generator sample we append it to our existing list of generator samples. Then rinse and repeat.  The key difference between the generator and the discriminator $\\theta$'s sampling is that we include x from our dataset for the discriminator (which is expected given our definition of the discriminator in the previous sections). After running this algorithm iteratively, the authors produce a set of posterior  $\\theta_d$ and $\\theta_g$ samples. They note the need for burnin here as samples tend to get more robust overtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian GAN Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate the *key* algorithms that are used to train the Bayesian GAN. There are a few details that we will omit for clarity of exposition, and refer our reader to the original paper for further discussion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised: Four Shapes Dataset (https://www.kaggle.com/smeschke/four-shapes/version/2#shapes.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to have a bit of and fun and train the GAN on a simple dataset of 200x200 black-and-white images of four different shapes: circles, rectangles, triangles, and stars (each rotated, scaled, and translated to provide variety). We chose this dataset because it has four clear modes, and we wanted to see if Bayesgan would properly model this. We follow the instructions described at: https://github.com/andrewgordonwilson/bayesgan, and complete our work in the repo: https://github.com/dylanrandle/bayesgan.\n",
    "\n",
    "First, download and extract the four shapes dataset into `bayesgan/datasets`. We provide a little script to convert the images to numpy arrays and save them as .npy files, `bayesgan/save_shapes.py` which you should run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "import os, glob, cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if not os.path.isdir(\"four_shapes\"):\n",
    "    os.mkdir(\"four_shapes\")\n",
    "\n",
    "circles = list(sorted(glob.glob(os.path.join('circle/', '*.png'))))\n",
    "triangles = list(sorted(glob.glob(os.path.join('triangle/', '*.png'))))\n",
    "squares = list(sorted(glob.glob(os.path.join('square/', '*.png'))))\n",
    "stars = list(sorted(glob.glob(os.path.join('star/', '*.png'))))\n",
    "shapes = [circles, triangles, squares, stars]\n",
    "\n",
    "img_inputs = []\n",
    "for shape in shapes:\n",
    "    for f in shape:\n",
    "        img = cv2.imread(f, 0)\n",
    "        img = img.astype(float)/255.\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "        img_inputs.append(img)\n",
    "\n",
    "img_inputs = np.array(img_inputs)\n",
    "img_train, img_test = train_test_split(img_inputs, test_size=0.2)\n",
    "\n",
    "print('train shape', img_train.shape)\n",
    "print('test shape', img_test.shape)\n",
    "\n",
    "np.save('four_shapes/train_shapes.npy', img_train)\n",
    "np.save('four_shapes/test_shapes.npy', img_test)\n",
    "\n",
    "fake_ytrain = np.zeros(shape=img_train.shape[0], dtype=int)\n",
    "fake_ytest = np.zeros(shape=img_test.shape[0], dtype=int)\n",
    "\n",
    "print('y train shape', fake_ytrain.shape)\n",
    "print('y test shape', fake_ytest.shape)\n",
    "\n",
    "np.save('four_shapes/train_labels.npy', fake_ytrain)\n",
    "np.save('four_shapes/test_labels.npy', fake_ytest)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a dataset class in `bgan_utils.py`, as described in the original repo:\n",
    "\n",
    "``` python\n",
    "class FourShapes():\n",
    "    def __init__(self):\n",
    "        self.imgs = np.load('datasets/four_shapes/train_shapes.npy')\n",
    "        self.test_imgs = np.load('datasets/four_shapes/test_shapes.npy')\n",
    "        self.labels = np.load('datasets/four_shapes/train_labels.npy')\n",
    "        self.test_labels = np.load('datasets/four_shapes/test_labels.npy')\n",
    "        self.labels = one_hot_encoded(self.labels, 4)\n",
    "        self.test_labels = one_hot_encoded(self.test_labels, 4)\n",
    "        self.x_dim = [200, 200, 1] # img dims\n",
    "        self.num_classes = 4\n",
    "        self.dataset_size = self.imgs.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_batch(batch_size, x, y):\n",
    "        \"\"\"Returns a batch from the given arrays.\n",
    "        \"\"\"\n",
    "        idx = np.random.choice(range(x.shape[0]), size=(batch_size,), replace=False)\n",
    "        return x[idx], y[idx]\n",
    "\n",
    "    def next_batch(self, batch_size, class_id=None):\n",
    "        return self.get_batch(batch_size, self.imgs, self.labels)\n",
    "\n",
    "    def test_batch(self, batch_size):\n",
    "        return self.get_batch(batch_size, self.test_imgs, self.test_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make two modifications to `run_bgan.py`: \n",
    "``` python\n",
    "from bgan_util import FourShapes\n",
    "```\n",
    "...\n",
    "```python\n",
    "elif args.dataset == 'four_shapes':\n",
    "    dataset = FourShapes()\n",
    "```\n",
    "and we are ready to go. From the top-level of `bayesgan`, simply run:\n",
    "``` bash\n",
    "./run_bgan.py --data_path datasets/four_shapes --dataset four_shapes --z_dim 10 --num_mcmc 2 --out_dir four_shape_unsup --train_iter 5000 --save_samples --n_save 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-supervised: CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to see how the semi-supervised results on MNIST would translate to the CIFAR-10 dataset. So we ran this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highlight the advantages of using Bayesian GAN vs. regular GAN and where we see disadvantages (authors dont mention any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final takeaways from the paper and its replicability. Some thoughts from the team on the viability of the author's approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gratuitous Titular Reference:\n",
    "The painting below is titled [Potrait of Edmond Belamy](https://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx) by Obvious, 2018. This portrait is part of the La Famille de Belamy series created via GAN. It was the first artwork created by AI to be auctioned and sold at Christie's for USD434,000 in October of 2018. In the same auction, several of Andy Warhol's prints sold under USD50,000 and Roy Lichtenstein's Crying Girl sold for [USD87,500](https://www.christies.com/prints-and-multiples-27814.aspx?saletitle=). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"400\" length='700' alt=\"portfolio_view\" src=Edmond_Belamy1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Papers Refrenced in this Tutorial: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Goodfellow I. et al. 2014. Generative Adversarial Networks. arXiv:1406.2661 [stat.ML]. url:https://arxiv.org/abs/1406.2661\n",
    "<br>\n",
    "2.Radfod A., Metz L., and Chintala S. 2015. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv:1511.06434 [cs.LG]. url: https://arxiv.org/abs/1511.06434\n",
    "<br>\n",
    "3.Salimans T. et al. 2016. Improved Techniques for Training GANs. arXiv:1606.03498 [cs.LG]. url:https://arxiv.org/abs/1606.03498\n",
    "<br>\n",
    "4.Chen T., Fox E., Guestrin C. 2014. Stochastic Gradient Hamiltonian Monte Carlo. arXiv:1402.4102 [stat.ME]. url: https://arxiv.org/abs/1402.4102\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
