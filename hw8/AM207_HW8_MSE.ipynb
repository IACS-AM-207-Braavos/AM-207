{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date:** Saturday, November 3rd, 2018 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers in the form of a Jupyter notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "\n",
    "** Place the name of everyone who's submitting this assignment here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import cm\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: In the AM207 Nursery We Help Canadians Smoke Trees with Purple Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some coding required**\n",
    "\n",
    "**This is part 1 of a 2 part problem.  You'll see the second part in a later problem set...**\n",
    "\n",
    "A plant nursery in Cambridge is exprimentally cross-breeding two types of hibiscus flowers: blue and pink. The goal is to create an exotic flower whose petals are pink with a ring of blue on each. \n",
    "\n",
    "There are four types of child plant that can result from this cross-breeding: \n",
    "\n",
    "  - Type 1: blue petals\n",
    "  - Type 2: pink petals \n",
    "  - Type 3: purple petals\n",
    "  - Type 4: pink petals with a blue ring on each (the desired effect). \n",
    "\n",
    "Out of 197 initial cross-breedings, the nursery obtained the following distribution over the four types of child plants: \n",
    "\n",
    "$$Y = (y_1, y_2, y_3, y_4) = (125, 18, 20, 34)$$\n",
    "\n",
    "where $y_i$ represents the number of child plants that are of type $i$.\n",
    "\n",
    "The nursery then consulted a famed Harvard plant geneticist, who informed them that the probability of obtaining each type of child plant in any single breeding experiment is as follows:\n",
    "\n",
    "$$ \\frac{\\theta+2}{4}, \\frac{1-\\theta}{4}, \\frac{1-\\theta}{4}, \\frac{\\theta}{4}.$$\n",
    "\n",
    "Unfortunately, the geneticist was unable to specify the quantity $\\theta$.\n",
    "\n",
    "Clearly, the nursery is interested in understanding how many cross-breeding they must perform, on average, in order to obtain a certain number of child plants with the exotic blue rings. To do this they must be able to compute $\\theta$. \n",
    "\n",
    "The owners of the nursery, being top students in AM207, decided to model the experiment in hopes of discovering $\\theta$ using the results from their 197 initial experiments. \n",
    "\n",
    "They chose to model the observed data using a multinomial model and thus calculated the likelihood to be:\n",
    "\n",
    "$$ p(y  \\vert  \\theta) \\propto (2+\\theta)^{y_1} (1-\\theta)^{y_2+y_3}  \\, \\theta^{y_4} $$\n",
    "\n",
    "\n",
    "The nursery owners decided to augment their model and hopefully obtain a friendlier looking distribution that allows for easy EM based maximum-likelihood finding and sampling (which you will do in next week's homework).\n",
    "\n",
    "They augment the data with a new variable $z$ such that:\n",
    "\n",
    "$$z + (y_1 - z) = y_1.$$\n",
    "\n",
    "That is, using the latent variable $z$, the number of type I child plants $y_1$ can be broken into two subtypes. Let the probability of obtaining the two subtype be $1/2$ and $\\theta/4$, respectively. $y_1$ can now be interpreted as to be the total number of trials in a binomial trial. Thus, the new likelihood can be written as\n",
    "\n",
    "$$ p(y, z  \\vert  \\theta) \\propto \\binom{y_{1}}{z} \\left (\\frac{1}{2} \\right )^{y_1-z} \\left(\\frac{\\theta}{4} \\right )^{z}  (1-\\theta)^{y_2+y_3}  \\, \\theta^{y_4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat the augmented model as a latent variable model.\n",
    "\n",
    "Write down an expression (up to unimportant constants - you must decide what unimportant means) for each of the following:\n",
    "\n",
    "1.1. The observed data log likelihood $\\mathcal{l}(y \\ \\vert \\ \\theta)$\n",
    "\n",
    "1.2. The complete data log likelihood $\\mathcal{L}(y, z\\ \\vert \\ \\theta)$\n",
    "\n",
    "1.3. The Auxilary function, $Q(\\theta, \\theta^{(t-1)})$, or the expected complete data log likelihood, defined by\n",
    "\n",
    "$$Q(\\theta, \\theta^{(t-1)}) = \\mathbb{E}_{Z  \\vert  Y=y, \\Theta = \\theta^{t-1}}[\\mathcal{L}(y, z\\ \\vert \\ \\theta)]$$\n",
    "\n",
    "1.4. Find an expression for $\\theta^{t} = \\text{argmax}_\\theta Q(\\theta, \\theta^{(t-1)})$ by maximizing the Auxilary function $Q(\\theta, \\theta^{(t-1)})$ given $\\theta, \\theta^{t-1}$ to find the optimal value for $\\theta^{t}$.  \n",
    "\n",
    "**Hint:** You don't actually need to do any difficult optimization for the M-step. After taking the expectation of the complete data log likelihood in the E-step, match your $Q(\\theta, \\theta^{(t-1)})$ to the log pdf of a familiar distribution, then use the known formula for the mode of this distribution to optimize $Q(\\theta, \\theta^{(t-1)})$.\n",
    "\n",
    "1.5. Use your forumulas from 1.3 and 1.4 for $Q(\\theta, \\theta^{t-1})$ and $\\theta^{t}$ to calculate the maximum likelihood through Expectation Maximization (EM). In order to perform EM, you must iterate through the following steps\n",
    "\n",
    "- (Expectation) Compute the Auxilary function, $Q(\\theta, \\theta^{t-1})$ (the expectation of the full data likelihood)\n",
    "- (Maximization) Compute $\\theta^{t} = \\text{argmax}_\\theta Q(\\theta, \\theta^{(t-1)})$\n",
    "\n",
    "Choose your own reasonable criterion for convergence to **estimate the MLE** of $\\theta$ using EM.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Gratuitous Titular Reference**:  Canada recently became the second country in the world to [legalize marijuana](https://www.cnn.com/2018/06/20/health/canada-legalizes-marijuana/index.html).  [Purple Stuff](https://www.amazon.com/Purple-Stuff-Soda-Relaxation-Beverage/dp/B00FF4AXTE) is a health beverage available on Amazon with a name and taste that's a tip of the hat to [Purple Drank](https://en.wikipedia.org/wiki/Purple_drank), the codeine infused beverage also popularly known as *lean* and is synonymous with the Houston hip hop scene (and in particular DJ Screw and his famous Chopped and Screwed style)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Predicting the Prior Like a Punch to the Kidneys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some coding required**\n",
    "\n",
    "In this problem we will work with the US Kidney Cancer Dataset (by county), a dataset of kidney cancer frequencies across the US over 5 years on a per county basis. \n",
    "\n",
    "The kidney cancer data can be found [here](./kcancer.csv).\n",
    "\n",
    "A casual inspection of the data might suggest that we independently model cancer rates for each of the provided counties.  Our experience in past homeworks/labs/lectures (in particular when we delved into the Rat Tumors problem) suggests potential drawbacks of conclusions based on raw cancer rates.  Addressing these drawbacks, let's look use a Bayesian model for our analysis of the data. In particular you will implement an Empircal Bayes model to examine the adjusted cancer rates per county.\n",
    "\n",
    "Let $N$ be the number of counties; let $y_j$ the number of kidney cancer case for the $j$-th county, $n_j$ the population of the $j$-th county and $\\theta_j$ the underlying kidney cancer rate for that county. We can construct a Bayesian model for our data as follows:\n",
    "\\begin{aligned}\n",
    "y_j &\\sim Poisson(5 \\cdot n_j \\cdot \\theta_j), \\quad j = 1, \\ldots, N\\\\\n",
    "\\theta_j &\\sim Gamma(\\alpha, \\beta), \\quad j = 1, \\ldots, N\n",
    "\\end{aligned}\n",
    "where $\\alpha, \\beta$ are hyper-parameters of the model.\n",
    "\n",
    "2.1. Consider the **prior-predictive** distribution (also called the evidence i.e. the denominator normalization in bayes theorem) of the model: $p(y) = \\int p(y \\vert \\theta) p(\\theta) d \\theta$. Why the prior-predictive? Because technically we \"haven't seen\" individual county data yet. And, our data are on the scale of $y$, not the rates $\\theta$. Write an expression for the negative binomial prior-predictive for this model.\n",
    "\n",
    "**Note:** Up until now we've had primarily thought about the posterior predictive: $\\int p( y \\vert \\theta) p(\\theta \\vert D) d\\theta$.  The posterior predictive and the prior predictive can be somewhat connected. In conjugate models such as ours, the two distributions have the same form.\n",
    "\n",
    "2.2. Implement Empirical Bayes via moment matching by matching the mean and the variance (central moments) of the negative binomial you calclated in 2.1 to the sample mean and variance from the data.  Find appropriate expressions/values for $\\alpha$ and $\\beta$. \n",
    "\n",
    "**Hint:** You need to be careful with the $5n_j$ multiplier.\n",
    "\n",
    "2.3. Use the values of $\\alpha$ and $\\beta$ you derived in 2.2 to generate 5000 posterior samples for the kidney cancer rates for each county.  Use these samples to generate a posterior mean rate for each county.\n",
    "\n",
    "2.4. Produce a scatter plot of the raw cancer rates (pct mortality) vs the county population size. Highlight the top 300 raw cancer rates in red. Highlight the bottom 300 raw cancer rates in blue. Finally, on the same plot add a scatter plot visualization of the posterior mean cancer rate estimates (pct mortality) vs the county population size, highlight these in green.\n",
    "\n",
    "2.5. Using the above scatter plot, explain why using the posterior means from our model to estimate cancer rates is preferable to studying the raw rates themselves.\n",
    "\n",
    "**Hint:** You might also find it helpful to follow the Rat Tumor example.\n",
    "\n",
    "\n",
    "**Gratuitous Pop Culture Bayesian Reference**: \n",
    "\n",
    "![](https://www.explainxkcd.com/wiki/images/b/bd/modified_bayes_theorem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Martin Garrix, Tiesto, Marshmello on the 1s and 2s.  Is that a Mixture of Experts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some coding required**\n",
    "\n",
    "What if you had to predict a one-to-many function? The data provided below comes from a dataset generated by Chris Bishop (yes that Bishop) to explain the models mentioned in the title above. We have included a pdf from his book which describe these models in some detail. This problem will continure in future homework where we shall learn to sample from this model and also how to solve it using mixture density networks.\n",
    "\n",
    "We read this data in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.050424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.042375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.038596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.019352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target         x\n",
       "0  0.000000  0.018727\n",
       "1  0.001001  0.050424\n",
       "2  0.002002  0.042375\n",
       "3  0.003003  0.038596\n",
       "4  0.004004  0.019352"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"one-to-many.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then plot it. Notice both the uneven sampling (more towards the center), and the \"more than one y\" for a given x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.x, df.target, '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal regression approaches to modeling such a function wont work, as they expect the function to be a proper mathematical function, that is, single valued.\n",
    "\n",
    "These kind of problems are called **inverse problems**, where more than one input state leads to an output state, and we have to try and model these multiple input states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mixture of gaussians (or other distributions) might is a sensible way to do this.\n",
    "\n",
    "You choose one of the gaussians with some probability. The nean of the gaussian is then given by some regression function, say for example a straight line. We could additionally fix the standard deviation or model it as well. \n",
    "\n",
    "Thus, for each component Gaussian, we choose a functional form for the mean and standard deviation. So our model looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)  = \\sum_i \\lambda_i g_i (x) $$\n",
    "\n",
    "Say we fit a model with 3 gaussians to this data. Such a model cannot fit the function above. Notice for example that at $x=0.2$ only one of the gaussians will dominate, different from the situation at $x=0.5$. This means that the probabilities of \"belonging\" to one or the other gaussians is also changing with $x$.\n",
    "\n",
    "If we allow the mixing probabilities to depend on $x$, we can model this situation.\n",
    "\n",
    "$$f(x)  = \\sum_i \\lambda_i (x) g_i (x) $$\n",
    "\n",
    "Such a model is called a \"mixture of experts\" model. The idea is that one \"expert\" gaussian is responsible in one sector of the feature space, while another expert is responsible in another sector.\n",
    "\n",
    "You can think of this model as implementing a \"standard\" gaussian mixture at each \"point\" x, with the added complexity that all of the means, standard deviations, and mixture probabilities change from one x to another.\n",
    "\n",
    "See https://www.cs.toronto.edu/~hinton/absps/hme.pdf and http://www.ee.hacettepe.edu.tr/~eyuksel/Publications/2012_TwentyYearsofMixtureofExperts.pdf for more details. I found the latter clearer and easier to understand.\n",
    "\n",
    "For this entire question you might find diagram code from [here](https://github.com/hardmaru/pytorch_notebooks/blob/master/mixture_density_networks.ipynb) useful. Take with attribution.\n",
    "\n",
    "We will assume we have **3 gaussians**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Linear Regression Mixture of Experts Model\n",
    "\n",
    "The basic idea, illustrated below, is to fit piecewise linear regressions iteratively in a EM style algorithm.\n",
    "\n",
    "![](https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlo4e4ari3r4wd%2Fj9vjyzv62x149%2Fjnsuyq59tar%2Fmixreg0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm looks like this: \n",
    "\n",
    "- Initialize the 1000 points in this dataset as randomly belonging to one of 3 \"classes\" or \"clusters\" or \"experts\". This takes a x-data problem and augments it with a fake z data point that tells us whether the point belongs in cluster 0, 1, or 2. (It helps convergence to say that points in the leftmost 0.2 belong to cluster 0 and righmost 0.2 to cluster 2).\n",
    "\n",
    "- With the fake z's in hand the 1000 points can be separated (based on cluster assignment) into 3 sets of points and used to fit 3 linear regression models. \n",
    "\n",
    "- Predictions can be made for all 1000 points on the data for each of the 3 regression lines. Reassign each data point to a cluster by choosing the cluster that minimizes the prediction error based on the squared distances between its actual y value and the 3 cluster predictions.\n",
    "\n",
    "- Rinse and repeat.\n",
    "\n",
    "3.1. We stated that \"*It helps convergence to say that points in the leftmost 0.2 belong to cluster 0 and righmost 0.2 to cluster 2*\".  Why might it help convergence to define an initial cluster assignment as opposed to random assignment?\n",
    "\n",
    "3.2. Specify a potential convergence criterion to use.  Why might you choose it?\n",
    "\n",
    "3.3. Implement the algorithm we described along with the convergence criterion you chose in 3.2.  You can use a linear regression fitter of your choice (statsmodels, sklearn, your own...).\n",
    "\n",
    "3.4. Apply your algorithm in the data in the `df` dataframe to produce a diagram like the one above which illustrates the straight line fits as well as the cluster belonging. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for those who want to read more** The mixture of experts can be implemented using Expectation Maximization using iteratively-reweighted least squares. Our method in A was merely an approximation to this process. You can find update equations [here](https://people.eecs.berkeley.edu/~jordan/papers/jordan-xu.ps)\n",
    "\n",
    "**Gratuitous Titular Reference**:  [DJs](https://martingarrix.com/), [DJs](https://www.tiesto.com/), [DJs](https://marshmellomusic.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
